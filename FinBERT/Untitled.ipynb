{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ar\\.conda\\envs\\finbert\\lib\\site-packages\\scipy\\__init__.py:149: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.16.3\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from finbert.finbert import predict\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "#import argparse\n",
    "import os\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/15/2022 16:59:36 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   tokens: [CLS] if you have a question at this time please press the one key on your touch - tone telephone . [SEP]\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   input_ids: 101 2065 2017 2031 1037 3160 2012 2023 2051 3531 2811 1996 2028 3145 2006 2115 3543 1011 4309 7026 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:36 - INFO - root -   tensor([[-1.2236, -1.0486,  2.6323],\n",
      "        [-1.4611, -0.6312,  2.1991],\n",
      "        [-0.8349, -1.7001,  2.5992],\n",
      "        [-0.5941, -1.9880,  2.7095],\n",
      "        [-0.9149, -1.4606,  2.8106]])\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   tokens: [CLS] please go ahead . [SEP]\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   input_ids: 101 3531 2175 3805 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:36 - INFO - root -   tensor([[-0.4671, -2.1383,  2.5671],\n",
      "        [-0.1949, -2.1159,  2.0639],\n",
      "        [-0.1696, -1.9057,  1.7638],\n",
      "        [-1.1477, -1.1826,  2.7468],\n",
      "        [-0.8289, -0.5038,  0.4756]])\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   tokens: [CLS] can you elaborate on whether those are to be recaptured on 1 ##q or are those on a permanently postponed basis . [SEP]\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   input_ids: 101 2064 2017 9603 2006 3251 2216 2024 2000 2022 23838 2006 1015 4160 2030 2024 2216 2006 1037 8642 14475 3978 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:36 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:37 - INFO - root -   tensor([[-1.4640, -0.8266,  2.4791],\n",
      "        [-1.7353,  0.1180,  1.1699],\n",
      "        [-1.9643,  0.2462,  1.3680],\n",
      "        [-1.8799,  0.5121,  0.7421],\n",
      "        [-1.2968, -0.5365,  1.7316]])\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   tokens: [CLS] then as far as the short ##fall in 4 ##q , you talked about impact from slow down of construction , show down reduced pricing power in the auto glass significant . [SEP]\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   input_ids: 101 2059 2004 2521 2004 1996 2460 13976 1999 1018 4160 1010 2017 5720 2055 4254 2013 4030 2091 1997 2810 1010 2265 2091 4359 20874 2373 1999 1996 8285 3221 3278 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:37 - INFO - root -   tensor([[-1.5665,  0.8301, -0.0346],\n",
      "        [-1.5069, -0.7125,  2.0378],\n",
      "        [-1.2903, -0.2849,  1.1911],\n",
      "        [-0.7107, -1.7864,  1.8251],\n",
      "        [-0.4493, -1.6060,  1.5515]])\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   tokens: [CLS] then lastly on the buy ##back , last year you had 1 . 5 m share buy - back program . [SEP]\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   input_ids: 101 2059 22267 2006 1996 4965 5963 1010 2197 2095 2017 2018 1015 1012 1019 1049 3745 4965 1011 2067 2565 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:37 - INFO - root -   tensor([[-0.0704, -2.6566,  2.4762],\n",
      "        [-0.1839, -2.7494,  2.5602],\n",
      "        [-0.7520, -1.2637,  1.8022],\n",
      "        [-0.6761, -2.0820,  2.8962],\n",
      "        [-1.3862, -0.8815,  2.4634]])\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   tokens: [CLS] so i would put a range on it from , in order to be non ##di ##lu ##tive we would have to purchase somewhere between 300 , 000 - 500 , 000 shares . [SEP]\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   input_ids: 101 2061 1045 2052 2404 1037 2846 2006 2009 2013 1010 1999 2344 2000 2022 2512 4305 7630 6024 2057 2052 2031 2000 5309 4873 2090 3998 1010 2199 1011 3156 1010 2199 6661 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:37 - INFO - root -   tensor([[-0.4849, -2.3240,  2.7423],\n",
      "        [-1.3824, -0.1377,  0.7552],\n",
      "        [-1.6033, -0.5102,  1.7289],\n",
      "        [ 1.1355, -2.8408,  1.4131],\n",
      "        [-0.4493, -1.6060,  1.5515]])\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   tokens: [CLS] so it ' s safe to say probably not early in the f ##y . [SEP]\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   input_ids: 101 2061 2009 1005 1055 3647 2000 2360 2763 2025 2220 1999 1996 1042 2100 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/15/2022 16:59:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:37 - INFO - root -   tensor([[-1.3575, -0.8942,  2.1049],\n",
      "        [-1.2761,  0.5341,  0.6371],\n",
      "        [-0.4323, -1.7956,  1.7600],\n",
      "        [ 0.4220, -2.1624,  1.4514],\n",
      "        [-1.0848, -1.3148,  2.6443]])\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   tokens: [CLS] please go ahead , . [SEP]\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   input_ids: 101 3531 2175 3805 1010 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:37 - INFO - root -   tensor([[-1.0456, -1.3179,  2.7142],\n",
      "        [ 0.0877, -1.8719,  1.5537],\n",
      "        [ 0.3101, -2.7213,  2.1464],\n",
      "        [-0.2507, -2.3897,  2.4594],\n",
      "        [-1.3430, -0.8365,  2.1251]])\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   tokens: [CLS] the sale of the facility for large scale optical was the building in orlando . [SEP]\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   input_ids: 101 1996 5096 1997 1996 4322 2005 2312 4094 9380 2001 1996 2311 1999 10108 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:37 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:38 - INFO - root -   tensor([[-0.9741, -1.3942,  2.8982],\n",
      "        [ 0.3293, -3.0345,  2.5445],\n",
      "        [-1.0498, -1.3504,  2.8032],\n",
      "        [ 0.1042, -2.6567,  2.3005],\n",
      "        [-1.7014,  0.0144,  1.0183]])\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   tokens: [CLS] like in 4 ##q , cash flow , proceeds from the sale of property is my guess is next year and the year after we would probably have anywhere from $ 4 - 9 ##m left , depending on , we are actually evaluating a couple of them but , you know , it wo n ' t be very significant . [SEP]\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   input_ids: 101 2066 1999 1018 4160 1010 5356 4834 1010 10951 2013 1996 5096 1997 3200 2003 2026 3984 2003 2279 2095 1998 1996 2095 2044 2057 2052 2763 2031 5973 2013 1002 1018 1011 1023 2213 2187 1010 5834 2006 1010 2057 2024 2941 23208 1037 3232 1997 2068 2021 1010 2017 2113 1010 2009 24185 1050 1005 1056 2022 2200 3278 1012 102\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:38 - INFO - root -   tensor([[-4.0349e-01, -2.2270e+00,  2.4652e+00],\n",
      "        [-4.4934e-01, -1.6060e+00,  1.5515e+00],\n",
      "        [ 1.9287e+00, -2.3956e+00,  3.8870e-01],\n",
      "        [ 2.1787e-03, -1.9684e+00,  1.4810e+00],\n",
      "        [-2.1765e-01, -2.0360e+00,  2.1273e+00]])\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   tokens: [CLS] most of it has to do , it all has to do with value - added glass , putting coating ##s on the glass that are enhancing the reflection properties for picture framing and video projection television , or video displays . [SEP]\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   input_ids: 101 2087 1997 2009 2038 2000 2079 1010 2009 2035 2038 2000 2079 2007 3643 1011 2794 3221 1010 5128 18898 2015 2006 1996 3221 2008 2024 20226 1996 9185 5144 2005 3861 20241 1998 2678 13996 2547 1010 2030 2678 8834 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:38 - INFO - root -   tensor([[-0.2724, -2.6248,  2.7460],\n",
      "        [ 1.7685, -2.7467,  0.9865],\n",
      "        [ 2.1700, -2.6334,  0.7174],\n",
      "        [-0.0452, -2.6952,  2.4027],\n",
      "        [ 1.8088, -2.2963,  0.4044]])\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   tokens: [CLS] shane , this is mike . [SEP]\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   input_ids: 101 8683 1010 2023 2003 3505 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:38 - INFO - root -   tensor([[-0.2507, -2.3897,  2.4594],\n",
      "        [-1.8721,  1.2572,  0.1356],\n",
      "        [-1.9005,  2.4121, -1.1152],\n",
      "        [ 0.1190, -2.5873,  1.9641],\n",
      "        [ 2.2446, -2.5495,  0.6086]])\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   tokens: [CLS] i was just curious , i think 1 ##q ##0 ##4 seems like you ' ve got a fairly easy com ##p there based on 1 ##q ##0 ##3 and you were talking about 8 - 10 % growth . [SEP]\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   input_ids: 101 1045 2001 2074 8025 1010 1045 2228 1015 4160 2692 2549 3849 2066 2017 1005 2310 2288 1037 7199 3733 4012 2361 2045 2241 2006 1015 4160 2692 2509 1998 2017 2020 3331 2055 1022 1011 2184 1003 3930 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:38 - INFO - root -   tensor([[-1.6999e-03, -2.3826e+00,  1.8714e+00],\n",
      "        [ 7.1298e-01, -2.1276e+00,  8.8654e-01],\n",
      "        [-8.4473e-01, -1.0939e+00,  1.8284e+00],\n",
      "        [-4.2669e-01, -1.8176e+00,  2.1720e+00],\n",
      "        [-4.4934e-01, -1.6060e+00,  1.5515e+00]])\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   tokens: [CLS] thank you . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/15/2022 16:59:38 - INFO - finbert.utils -   input_ids: 101 4067 2017 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:38 - INFO - root -   tensor([[ 0.4220, -2.1624,  1.4514],\n",
      "        [-0.6904, -1.9689,  2.6934],\n",
      "        [-0.4671, -2.1383,  2.5671],\n",
      "        [ 0.8270, -2.3443,  1.3516],\n",
      "        [ 1.3887, -2.0578,  0.4564]])\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   tokens: [CLS] a couple of questions . [SEP]\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   input_ids: 101 1037 3232 1997 3980 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:38 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:39 - INFO - root -   tensor([[-1.1922, -0.7563,  2.0424],\n",
      "        [-0.5088, -2.1113,  2.8353],\n",
      "        [-0.8871, -1.3857,  1.9230],\n",
      "        [-1.0432, -1.2143,  2.7691],\n",
      "        [-0.2525, -2.3168,  2.3759]])\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   tokens: [CLS] if you recall we actually kind of shut down - l ##sb - ina ##udi ##ble - rs ##b - about a year ago , a year and a half ago now . [SEP]\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   input_ids: 101 2065 2017 9131 2057 2941 2785 1997 3844 2091 1011 1048 19022 1011 27118 21041 3468 1011 12667 2497 1011 2055 1037 2095 3283 1010 1037 2095 1998 1037 2431 3283 2085 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:39 - INFO - root -   tensor([[-1.9721,  0.5790,  0.9323],\n",
      "        [ 1.4239, -2.8485,  1.3103],\n",
      "        [ 2.2148, -2.4605,  0.5174],\n",
      "        [-0.3168, -2.3168,  2.6060],\n",
      "        [ 1.1645, -2.9636,  1.5278]])\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   tokens: [CLS] using - l ##sb - ina ##udi ##ble - rs ##b - takes we would have the right of first refusal . [SEP]\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   input_ids: 101 2478 1011 1048 19022 1011 27118 21041 3468 1011 12667 2497 1011 3138 2057 2052 2031 1996 2157 1997 2034 13948 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:39 - INFO - root -   tensor([[-0.2125, -2.6026,  2.6640],\n",
      "        [ 1.9026, -2.6142,  0.8555],\n",
      "        [ 2.0327, -2.5717,  0.6986],\n",
      "        [-0.0438, -2.6145,  2.4428],\n",
      "        [ 1.1462, -2.5966,  0.9913]])\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   tokens: [CLS] great . [SEP]\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   input_ids: 101 2307 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:39 - INFO - root -   tensor([[-0.1178, -1.1340,  0.7273],\n",
      "        [-0.6112, -1.9662,  2.4642],\n",
      "        [-0.8338, -0.8066,  0.9500],\n",
      "        [-0.4913, -1.9170,  1.6478],\n",
      "        [-1.1819, -1.1225,  2.3340]])\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   tokens: [CLS] we are optimistic it will be released but given the uncertainty of dealing with french courts we ca n ' t be con ##clusive on that matter . [SEP]\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   input_ids: 101 2057 2024 21931 2009 2097 2022 2207 2021 2445 1996 12503 1997 7149 2007 2413 5434 2057 6187 1050 1005 1056 2022 9530 23633 2006 2008 3043 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:39 - INFO - root -   tensor([[-1.5941,  0.0338,  1.1472],\n",
      "        [-0.7029, -1.9981,  2.0460],\n",
      "        [-2.0540,  2.5096, -1.2040],\n",
      "        [-0.2551, -2.0495,  1.6097],\n",
      "        [-1.5503, -0.1270,  1.1651]])\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   *** Example ***\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   guid: 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   tokens: [CLS] that ' s what we know about it . [SEP]\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   input_ids: 101 2008 1005 1055 2054 2057 2113 2055 2009 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "02/15/2022 16:59:39 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "02/15/2022 16:59:39 - INFO - root -   tensor([[-0.5226, -2.2058,  2.5847],\n",
      "        [ 0.2924, -2.7599,  2.1653],\n",
      "        [-0.4493, -1.6060,  1.5515],\n",
      "        [-0.0421, -2.2755,  1.6659]])\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/finbert-sentiment\"\n",
    "output_path = \"output/\"\n",
    "input_file =  \"test_ssplit.txt\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "with open(input_file,'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,num_labels=3,cache_dir=None)\n",
    "\n",
    "#output = \"predictions.csv\"\n",
    "pred_finb = predict(text,model,write_to_csv=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>logit</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you have a question at this time please pre...</td>\n",
       "      <td>[0.02021729, 0.024083477, 0.95569927]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.003866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If your question has been answered or you wish...</td>\n",
       "      <td>[0.023718204, 0.054388512, 0.92189324]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.030670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once again , if you have a question at this ti...</td>\n",
       "      <td>[0.030840278, 0.0129828695, 0.9561768]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One moment please for our first question .</td>\n",
       "      <td>[0.035138335, 0.008718041, 0.95614356]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.026420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our first question is from Eric Martinuzzi fro...</td>\n",
       "      <td>[0.02321826, 0.013453697, 0.96332806]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.009765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Please go ahead .</td>\n",
       "      <td>[0.045512654, 0.008557095, 0.94593024]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.036956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Good morning , gentlemen .</td>\n",
       "      <td>[0.09330615, 0.013665283, 0.8930285]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.079641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Morning Eric .</td>\n",
       "      <td>[0.123628214, 0.021783257, 0.85458845]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.101845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My first question has to do with the architect...</td>\n",
       "      <td>[0.019571118, 0.018900193, 0.96152866]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I know part of the reason for the short fall o...</td>\n",
       "      <td>[0.16474319, 0.22802936, 0.60722744]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.063286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Can you elaborate on whether those are to be r...</td>\n",
       "      <td>[0.01835772, 0.034724545, 0.9469178]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>For the most part they are just delayed .</td>\n",
       "      <td>[0.03898809, 0.24877743, 0.7122345]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.209789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>There was one significant project which was be...</td>\n",
       "      <td>[0.026229907, 0.23921971, 0.73455036]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.212990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>But with did n't see very many , I do n't thin...</td>\n",
       "      <td>[0.038913526, 0.42551956, 0.535567]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.386606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>They 've been pushed into 1Q and 2Q .</td>\n",
       "      <td>[0.04201278, 0.089858174, 0.8681291]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.047845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Then as far as the shortfall in 4Q , you talke...</td>\n",
       "      <td>[0.060197458, 0.66127765, 0.2785249]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.601080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Any measurable impact due to weather .</td>\n",
       "      <td>[0.026424807, 0.05848188, 0.9150933]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.032057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The weather impact was certainly a concern as ...</td>\n",
       "      <td>[0.06373393, 0.1741707, 0.7620954]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.110437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>We actually , we had some effect but it was n'...</td>\n",
       "      <td>[0.07159563, 0.024419092, 0.90398526]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.047177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Okay .</td>\n",
       "      <td>[0.11481631, 0.036112186, 0.84907156]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.078704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Then lastly on the buyback , last year you had...</td>\n",
       "      <td>[0.0722616, 0.005441605, 0.92229676]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.066820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>You did mention that you would have some sort ...</td>\n",
       "      <td>[0.06014025, 0.004623678, 0.93523604]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.055517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Can you put some numbers around hat for us ?</td>\n",
       "      <td>[0.069149025, 0.041455846, 0.8893952]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.027693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The management incentive options are , the pro...</td>\n",
       "      <td>[0.027143843, 0.006653901, 0.9662023]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.020490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The number of shares that are exercised are le...</td>\n",
       "      <td>[0.020148352, 0.033376228, 0.94647545]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.013228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>So I would put a range on it from , in order t...</td>\n",
       "      <td>[0.037926696, 0.0060285567, 0.95604473]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.031898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>But even the timing of that and , we would not...</td>\n",
       "      <td>[0.07720832, 0.26807755, 0.6547141]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.190869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>We would not want to do that during times wher...</td>\n",
       "      <td>[0.031267222, 0.09328826, 0.8754445]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.062021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>So we are committed to that but we will manage...</td>\n",
       "      <td>[0.42758417, 0.008019509, 0.5643963]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.419565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Okay .</td>\n",
       "      <td>[0.11481631, 0.036112186, 0.84907156]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.078704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Written well .</td>\n",
       "      <td>[0.70150816, 0.022345914, 0.27614594]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.679162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>A couple of questions .</td>\n",
       "      <td>[0.03579019, 0.055340692, 0.90886915]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.019551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Could you provide a little more detail on the ...</td>\n",
       "      <td>[0.03385777, 0.0068185683, 0.95932364]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.027039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>What it was that you gave up , and why you cho...</td>\n",
       "      <td>[0.05489111, 0.033336706, 0.9117722]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.021554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>And I have a few follow-ups .</td>\n",
       "      <td>[0.021232799, 0.017893957, 0.96087325]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Rob , this is Mike .</td>\n",
       "      <td>[0.06676247, 0.008472847, 0.9247647]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.058290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>If you recall we actually kind of shut down -L...</td>\n",
       "      <td>[0.03117617, 0.39970422, 0.56911963]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.368528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Since that point in time we have been very agg...</td>\n",
       "      <td>[0.52450746, 0.0073157824, 0.46817675]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.517192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>It just so happens that now is the time that w...</td>\n",
       "      <td>[0.8385779, 0.007818016, 0.15360403]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.830760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Does APOG retain value in any of that ?</td>\n",
       "      <td>[0.050689586, 0.0068601468, 0.9424502]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.043829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>No , what we retain , though , is upon , as th...</td>\n",
       "      <td>[0.40745878, 0.006565911, 0.5859753]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.400893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Using -LSB- inaudible -RSB- takes we would hav...</td>\n",
       "      <td>[0.053069152, 0.004862112, 0.94206876]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.048207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>It is interesting that the donation did go to ...</td>\n",
       "      <td>[0.7342733, 0.008021568, 0.25770512]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.726252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>This is something we always felt was important...</td>\n",
       "      <td>[0.7852957, 0.007859336, 0.20684499]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.777436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>It 's a long-term development before it gets b...</td>\n",
       "      <td>[0.07635153, 0.0058398307, 0.9178087]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.070512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>So this is a good way to see that done .</td>\n",
       "      <td>[0.5318715, 0.012599102, 0.4555294]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.519272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Great .</td>\n",
       "      <td>[0.27099776, 0.09808759, 0.6309147]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.172910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>On the discontinued ops , could you provide so...</td>\n",
       "      <td>[0.043638457, 0.011256602, 0.94510496]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.032382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Most of the discontinued ops improvements had ...</td>\n",
       "      <td>[0.12531035, 0.12876737, 0.7459223]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.003457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>And as such we have taken that down to the bon...</td>\n",
       "      <td>[0.10274899, 0.024694618, 0.8725564]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.078054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>you ca n't really put a timetable on it and un...</td>\n",
       "      <td>[0.028003411, 0.029719863, 0.9422767]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.001716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>We are optimistic it will be released but give...</td>\n",
       "      <td>[0.046295036, 0.23579791, 0.717907]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.189503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>so most of the other issues in Europe are now ...</td>\n",
       "      <td>[0.059174046, 0.016204042, 0.9246219]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.042970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>So our original rye serves are down , reserves...</td>\n",
       "      <td>[0.010073444, 0.96635693, 0.023569666]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.956284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Rob , last year our reserves would have been $...</td>\n",
       "      <td>[0.13120943, 0.021811921, 0.84697866]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.109398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>As far as cash out this year we know there wil...</td>\n",
       "      <td>[0.049354356, 0.20486017, 0.7457854]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.155506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>That 's what we know about it .</td>\n",
       "      <td>[0.04246905, 0.007889697, 0.94964117]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.034579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The rest of it , there 's still time , we are ...</td>\n",
       "      <td>[0.13237657, 0.006254783, 0.8613686]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.126122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Okay .</td>\n",
       "      <td>[0.11481631, 0.036112186, 0.84907156]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.078704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>And Mike you did say $ 4-9m in cash flows from...</td>\n",
       "      <td>[0.15093829, 0.01617489, 0.8328868]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.134763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0   If you have a question at this time please pre...   \n",
       "1   If your question has been answered or you wish...   \n",
       "2   Once again , if you have a question at this ti...   \n",
       "3          One moment please for our first question .   \n",
       "4   Our first question is from Eric Martinuzzi fro...   \n",
       "5                                   Please go ahead .   \n",
       "6                          Good morning , gentlemen .   \n",
       "7                                      Morning Eric .   \n",
       "8   My first question has to do with the architect...   \n",
       "9   I know part of the reason for the short fall o...   \n",
       "10  Can you elaborate on whether those are to be r...   \n",
       "11          For the most part they are just delayed .   \n",
       "12  There was one significant project which was be...   \n",
       "13  But with did n't see very many , I do n't thin...   \n",
       "14              They 've been pushed into 1Q and 2Q .   \n",
       "15  Then as far as the shortfall in 4Q , you talke...   \n",
       "16             Any measurable impact due to weather .   \n",
       "17  The weather impact was certainly a concern as ...   \n",
       "18  We actually , we had some effect but it was n'...   \n",
       "19                                             Okay .   \n",
       "20  Then lastly on the buyback , last year you had...   \n",
       "21  You did mention that you would have some sort ...   \n",
       "22       Can you put some numbers around hat for us ?   \n",
       "23  The management incentive options are , the pro...   \n",
       "24  The number of shares that are exercised are le...   \n",
       "25  So I would put a range on it from , in order t...   \n",
       "26  But even the timing of that and , we would not...   \n",
       "27  We would not want to do that during times wher...   \n",
       "28  So we are committed to that but we will manage...   \n",
       "29                                             Okay .   \n",
       "..                                                ...   \n",
       "69                                     Written well .   \n",
       "70                            A couple of questions .   \n",
       "71  Could you provide a little more detail on the ...   \n",
       "72  What it was that you gave up , and why you cho...   \n",
       "73                      And I have a few follow-ups .   \n",
       "74                               Rob , this is Mike .   \n",
       "75  If you recall we actually kind of shut down -L...   \n",
       "76  Since that point in time we have been very agg...   \n",
       "77  It just so happens that now is the time that w...   \n",
       "78            Does APOG retain value in any of that ?   \n",
       "79  No , what we retain , though , is upon , as th...   \n",
       "80  Using -LSB- inaudible -RSB- takes we would hav...   \n",
       "81  It is interesting that the donation did go to ...   \n",
       "82  This is something we always felt was important...   \n",
       "83  It 's a long-term development before it gets b...   \n",
       "84           So this is a good way to see that done .   \n",
       "85                                            Great .   \n",
       "86  On the discontinued ops , could you provide so...   \n",
       "87  Most of the discontinued ops improvements had ...   \n",
       "88  And as such we have taken that down to the bon...   \n",
       "89  you ca n't really put a timetable on it and un...   \n",
       "90  We are optimistic it will be released but give...   \n",
       "91  so most of the other issues in Europe are now ...   \n",
       "92  So our original rye serves are down , reserves...   \n",
       "93  Rob , last year our reserves would have been $...   \n",
       "94  As far as cash out this year we know there wil...   \n",
       "95                    That 's what we know about it .   \n",
       "96  The rest of it , there 's still time , we are ...   \n",
       "97                                             Okay .   \n",
       "98  And Mike you did say $ 4-9m in cash flows from...   \n",
       "\n",
       "                                      logit prediction  sentiment_score  \n",
       "0     [0.02021729, 0.024083477, 0.95569927]    neutral        -0.003866  \n",
       "1    [0.023718204, 0.054388512, 0.92189324]    neutral        -0.030670  \n",
       "2    [0.030840278, 0.0129828695, 0.9561768]    neutral         0.017857  \n",
       "3    [0.035138335, 0.008718041, 0.95614356]    neutral         0.026420  \n",
       "4     [0.02321826, 0.013453697, 0.96332806]    neutral         0.009765  \n",
       "5    [0.045512654, 0.008557095, 0.94593024]    neutral         0.036956  \n",
       "6      [0.09330615, 0.013665283, 0.8930285]    neutral         0.079641  \n",
       "7    [0.123628214, 0.021783257, 0.85458845]    neutral         0.101845  \n",
       "8    [0.019571118, 0.018900193, 0.96152866]    neutral         0.000671  \n",
       "9      [0.16474319, 0.22802936, 0.60722744]    neutral        -0.063286  \n",
       "10     [0.01835772, 0.034724545, 0.9469178]    neutral        -0.016367  \n",
       "11      [0.03898809, 0.24877743, 0.7122345]    neutral        -0.209789  \n",
       "12    [0.026229907, 0.23921971, 0.73455036]    neutral        -0.212990  \n",
       "13      [0.038913526, 0.42551956, 0.535567]    neutral        -0.386606  \n",
       "14     [0.04201278, 0.089858174, 0.8681291]    neutral        -0.047845  \n",
       "15     [0.060197458, 0.66127765, 0.2785249]   negative        -0.601080  \n",
       "16     [0.026424807, 0.05848188, 0.9150933]    neutral        -0.032057  \n",
       "17       [0.06373393, 0.1741707, 0.7620954]    neutral        -0.110437  \n",
       "18    [0.07159563, 0.024419092, 0.90398526]    neutral         0.047177  \n",
       "19    [0.11481631, 0.036112186, 0.84907156]    neutral         0.078704  \n",
       "20     [0.0722616, 0.005441605, 0.92229676]    neutral         0.066820  \n",
       "21    [0.06014025, 0.004623678, 0.93523604]    neutral         0.055517  \n",
       "22    [0.069149025, 0.041455846, 0.8893952]    neutral         0.027693  \n",
       "23    [0.027143843, 0.006653901, 0.9662023]    neutral         0.020490  \n",
       "24   [0.020148352, 0.033376228, 0.94647545]    neutral        -0.013228  \n",
       "25  [0.037926696, 0.0060285567, 0.95604473]    neutral         0.031898  \n",
       "26      [0.07720832, 0.26807755, 0.6547141]    neutral        -0.190869  \n",
       "27     [0.031267222, 0.09328826, 0.8754445]    neutral        -0.062021  \n",
       "28     [0.42758417, 0.008019509, 0.5643963]    neutral         0.419565  \n",
       "29    [0.11481631, 0.036112186, 0.84907156]    neutral         0.078704  \n",
       "..                                      ...        ...              ...  \n",
       "69    [0.70150816, 0.022345914, 0.27614594]   positive         0.679162  \n",
       "70    [0.03579019, 0.055340692, 0.90886915]    neutral        -0.019551  \n",
       "71   [0.03385777, 0.0068185683, 0.95932364]    neutral         0.027039  \n",
       "72     [0.05489111, 0.033336706, 0.9117722]    neutral         0.021554  \n",
       "73   [0.021232799, 0.017893957, 0.96087325]    neutral         0.003339  \n",
       "74     [0.06676247, 0.008472847, 0.9247647]    neutral         0.058290  \n",
       "75     [0.03117617, 0.39970422, 0.56911963]    neutral        -0.368528  \n",
       "76   [0.52450746, 0.0073157824, 0.46817675]   positive         0.517192  \n",
       "77     [0.8385779, 0.007818016, 0.15360403]   positive         0.830760  \n",
       "78   [0.050689586, 0.0068601468, 0.9424502]    neutral         0.043829  \n",
       "79     [0.40745878, 0.006565911, 0.5859753]    neutral         0.400893  \n",
       "80   [0.053069152, 0.004862112, 0.94206876]    neutral         0.048207  \n",
       "81     [0.7342733, 0.008021568, 0.25770512]   positive         0.726252  \n",
       "82     [0.7852957, 0.007859336, 0.20684499]   positive         0.777436  \n",
       "83    [0.07635153, 0.0058398307, 0.9178087]    neutral         0.070512  \n",
       "84      [0.5318715, 0.012599102, 0.4555294]   positive         0.519272  \n",
       "85      [0.27099776, 0.09808759, 0.6309147]    neutral         0.172910  \n",
       "86   [0.043638457, 0.011256602, 0.94510496]    neutral         0.032382  \n",
       "87      [0.12531035, 0.12876737, 0.7459223]    neutral        -0.003457  \n",
       "88     [0.10274899, 0.024694618, 0.8725564]    neutral         0.078054  \n",
       "89    [0.028003411, 0.029719863, 0.9422767]    neutral        -0.001716  \n",
       "90      [0.046295036, 0.23579791, 0.717907]    neutral        -0.189503  \n",
       "91    [0.059174046, 0.016204042, 0.9246219]    neutral         0.042970  \n",
       "92   [0.010073444, 0.96635693, 0.023569666]   negative        -0.956284  \n",
       "93    [0.13120943, 0.021811921, 0.84697866]    neutral         0.109398  \n",
       "94     [0.049354356, 0.20486017, 0.7457854]    neutral        -0.155506  \n",
       "95    [0.04246905, 0.007889697, 0.94964117]    neutral         0.034579  \n",
       "96     [0.13237657, 0.006254783, 0.8613686]    neutral         0.126122  \n",
       "97    [0.11481631, 0.036112186, 0.84907156]    neutral         0.078704  \n",
       "98      [0.15093829, 0.01617489, 0.8328868]    neutral         0.134763  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_finb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>logit</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Then as far as the shortfall in 4Q , you talke...</td>\n",
       "      <td>[0.060197458, 0.66127765, 0.2785249]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.601080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Also FY03 was a pretty low base if you recall .</td>\n",
       "      <td>[0.031943154, 0.7301952, 0.23786174]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.698252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>We just got , I mean ' 02 , we got completely ...</td>\n",
       "      <td>[0.012848866, 0.9589725, 0.028178697]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.946124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>So our original rye serves are down , reserves...</td>\n",
       "      <td>[0.010073444, 0.96635693, 0.023569666]</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.956284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "15  Then as far as the shortfall in 4Q , you talke...   \n",
       "56    Also FY03 was a pretty low base if you recall .   \n",
       "57  We just got , I mean ' 02 , we got completely ...   \n",
       "92  So our original rye serves are down , reserves...   \n",
       "\n",
       "                                     logit prediction  sentiment_score  \n",
       "15    [0.060197458, 0.66127765, 0.2785249]   negative        -0.601080  \n",
       "56    [0.031943154, 0.7301952, 0.23786174]   negative        -0.698252  \n",
       "57   [0.012848866, 0.9589725, 0.028178697]   negative        -0.946124  \n",
       "92  [0.010073444, 0.96635693, 0.023569666]   negative        -0.956284  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_finb[pred_finb.prediction == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.920424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.029212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.066076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.868590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.177148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.125688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.731645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction  sentiment_score\n",
       "0   positive         0.920424\n",
       "1    neutral         0.029212\n",
       "2    neutral         0.066076\n",
       "3   positive         0.868590\n",
       "4    neutral         0.177148\n",
       "5    neutral         0.125688\n",
       "6   positive         0.731645"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_finb[['prediction', 'sentiment_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.101844957"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.123628214- 0.021783257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_txt =text.splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rob , last year our reserves would have been $ 19.7 m they now are at $ 11.8 m , reduced with some payments for settlement throughout the year and then as we articulated this one , the ability to lower an exposure because of some favorable things of that happened in the courts .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_finb['sentence'][8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "split_txt = pd.DataFrame(split_txt)\n",
    "finb_txt = pred_finb[['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_txt = split_txt.rename(columns={'0':'sentence'})\n",
    "\n",
    "#split_txt[~split_txt.x1.isin(finb_txt.x1)]\n",
    "\n",
    "#outer_join = split_txt.merge(finb_txt, how = 'outer', indicator = True)\n",
    "\n",
    "#anti_join = outer_join[~(outer_join._merge == 'both')].drop('_merge', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>And I think that 's a testimony to , you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>And that , you know , we understand that our b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Eighty-five percent of the reductions were foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>And a lot of those had to do with decisions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>And I think that with regard to matters of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>In closing , I 'd like to say that , you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>But I think that the team will earn its stripe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Now , LeCroy 's management team has reacted ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>So we 're planning to stay the course on our s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>One is , can you just give us a little bit mor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence\n",
       "20  And I think that 's a testimony to , you know ...\n",
       "21  And that , you know , we understand that our b...\n",
       "22  Eighty-five percent of the reductions were foc...\n",
       "23  And a lot of those had to do with decisions th...\n",
       "24  And I think that with regard to matters of the...\n",
       "25  In closing , I 'd like to say that , you know ...\n",
       "26  But I think that the team will earn its stripe...\n",
       "27  Now , LeCroy 's management team has reacted ve...\n",
       "28  So we 're planning to stay the course on our s...\n",
       "29  One is , can you just give us a little bit mor..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finb_txt[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_txt = split_txt.set_axis(['sentence'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_join = split_txt.merge(finb_txt, how = 'outer', indicator = True)\n",
    "\n",
    "anti_join = outer_join[~(outer_join._merge == 'both')].drop('_merge', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>This is a very significant decision for Yahoo!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>This is a very significant decision for Yahoo!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Right this minute , it looks like North Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Right this minute , it looks like North Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>It was my understanding that on track meant th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>It was my understanding that on track meant th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>So when you say it 's an opportunity , it all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>So when you say it 's an opportunity , it all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>The cost cutting , or the cost realizations th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>The cost cutting , or the cost realizations th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Reauthorization , the current six year bill ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>Reauthorization , the current six year bill ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Reauthorization , the current six year bill ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Reauthorization , the current six year bill ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>The real issue is going to be the level of , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>The real issue is going to be the level of , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>So , some will bring that question to us at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>So , some will bring that question to us at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>I have a follow-up question , John can you giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>I have a follow-up question , John can you giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>You know , what you are seeing -LSB- Inaudible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>You know , what you are seeing -LSB- Inaudible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>So , we think people are willing to stand but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>So , we think people are willing to stand but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Just -LSB- Inaudible -RSB- as we are in techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>Just -LSB- Inaudible -RSB- as we are in techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Right this minute , it looks like North Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>Right this minute , it looks like North Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>This offer -LRB- ph -RRB- is down by about 30 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>This offer -LRB- ph -RRB- is down by about 30 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>It was my understanding that on track meant th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>It was my understanding that on track meant th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>, now , so what you said is that is that plant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>, now , so what you said is that is that plant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>So when you say it 's an opportunity , it all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>So when you say it 's an opportunity , it all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>I think it is true that Round Up has taken a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>I think it is true that Round Up has taken a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>Reauthorization , the current six year bill ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>Reauthorization , the current six year bill ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>So , some will bring that question to us at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>So , some will bring that question to us at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>For the quarter , it was a 24 percent of finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>You know , what you are seeing -LSB- Inaudible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>You know , what you are seeing -LSB- Inaudible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>Just -LSB- Inaudible -RSB- as we are in techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>Just -LSB- Inaudible -RSB- as we are in techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>We have presented ourselves in a small individ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>We have presented ourselves in a small individ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence\n",
       "120   This is a very significant decision for Yahoo!...\n",
       "121   This is a very significant decision for Yahoo!...\n",
       "254   Right this minute , it looks like North Americ...\n",
       "255   Right this minute , it looks like North Americ...\n",
       "756   It was my understanding that on track meant th...\n",
       "757   It was my understanding that on track meant th...\n",
       "802   So when you say it 's an opportunity , it all ...\n",
       "803   So when you say it 's an opportunity , it all ...\n",
       "804   The cost cutting , or the cost realizations th...\n",
       "805   The cost cutting , or the cost realizations th...\n",
       "1026  Reauthorization , the current six year bill ex...\n",
       "1027  Reauthorization , the current six year bill ex...\n",
       "1028  Reauthorization , the current six year bill ex...\n",
       "1029  Reauthorization , the current six year bill ex...\n",
       "1030  The real issue is going to be the level of , i...\n",
       "1031  The real issue is going to be the level of , i...\n",
       "1284  So , some will bring that question to us at an...\n",
       "1285  So , some will bring that question to us at an...\n",
       "1286  I have a follow-up question , John can you giv...\n",
       "1287  I have a follow-up question , John can you giv...\n",
       "1416  For the quarter , it was a 24 percent of finan...\n",
       "1417  For the quarter , it was a 24 percent of finan...\n",
       "1418  For the quarter , it was a 24 percent of finan...\n",
       "1419  For the quarter , it was a 24 percent of finan...\n",
       "1424  You know , what you are seeing -LSB- Inaudible...\n",
       "1425  You know , what you are seeing -LSB- Inaudible...\n",
       "1426  So , we think people are willing to stand but ...\n",
       "1427  So , we think people are willing to stand but ...\n",
       "1456  Just -LSB- Inaudible -RSB- as we are in techno...\n",
       "1457  Just -LSB- Inaudible -RSB- as we are in techno...\n",
       "...                                                 ...\n",
       "2108  Right this minute , it looks like North Americ...\n",
       "2109  Right this minute , it looks like North Americ...\n",
       "2110  This offer -LRB- ph -RRB- is down by about 30 ...\n",
       "2111  This offer -LRB- ph -RRB- is down by about 30 ...\n",
       "2112  It was my understanding that on track meant th...\n",
       "2113  It was my understanding that on track meant th...\n",
       "2114  , now , so what you said is that is that plant...\n",
       "2115  , now , so what you said is that is that plant...\n",
       "2116  So when you say it 's an opportunity , it all ...\n",
       "2117  So when you say it 's an opportunity , it all ...\n",
       "2118  I think it is true that Round Up has taken a l...\n",
       "2119  I think it is true that Round Up has taken a l...\n",
       "2120  Reauthorization , the current six year bill ex...\n",
       "2121  Reauthorization , the current six year bill ex...\n",
       "2122  So , some will bring that question to us at an...\n",
       "2123  So , some will bring that question to us at an...\n",
       "2124  For the quarter , it was a 24 percent of finan...\n",
       "2125  For the quarter , it was a 24 percent of finan...\n",
       "2126  For the quarter , it was a 24 percent of finan...\n",
       "2127  For the quarter , it was a 24 percent of finan...\n",
       "2128                                                  .\n",
       "2129                                                  .\n",
       "2130                                                  .\n",
       "2131                                                  .\n",
       "2132  You know , what you are seeing -LSB- Inaudible...\n",
       "2133  You know , what you are seeing -LSB- Inaudible...\n",
       "2134  Just -LSB- Inaudible -RSB- as we are in techno...\n",
       "2135  Just -LSB- Inaudible -RSB- as we are in techno...\n",
       "2136  We have presented ourselves in a small individ...\n",
       "2137  We have presented ourselves in a small individ...\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split_txt[~split_txt.sentence.isin(finb_txt.sentence)]\n",
    "anti_join"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
